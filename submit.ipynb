{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Clean training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('colwidth', 100)\n",
    "pd.set_option('max_columns', 300)\n",
    "pd.set_option('max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv('/Users/bonniechung/GoogleCloud/758T/project/raw_data/airbnb_train_x.csv', header = 0, index_col = 0, keep_default_na=False, dtype={\"zipcode\":str, 'maximum_nights':str, 'minimum_nights':str, 'availability_30':str, 'availability_60':str, 'availability_90':str, 'availability_365':str })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_y= pd.read_csv('/Users/bonniechung/GoogleCloud/758T/project/raw_data/airbnb_train_y.csv', header = 0, index_col = 0, keep_default_na=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_y,df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop missing or invalid records\n",
    "df.drop([16246,30584,47615,56281,65792,72540,75208,92585,96068], inplace = True)\n",
    "df.drop([95973,548,75600,73072], inplace = True)\n",
    "df.drop([13584, 24317, 29879, 44690, 51371, 63486, 76218, 85311, 90609,92028], inplace = True) # y wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "df.drop(['require_guest_profile_picture'], axis = 1, inplace = True) # All of the values are false\n",
    "df.drop(['square_feet'], axis = 1, inplace = True) # Having too less records\n",
    "df.drop(['experiences_offered'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change datatype of y variables\n",
    "df.iloc[:,0:2] = df.iloc[:,0:2].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the length of text data\n",
    "df['len_access']= df['access'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_description']= df['description'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_host_about']= df['host_about'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_house_rules']= df['house_rules'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_interaction']= df['interaction'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_name']= df['name'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_neighborhood_overview']= df['neighborhood_overview'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_notes']= df['notes'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_space']= df['space'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_summary']= df['summary'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_transit']= df['transit'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['description','host_about'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cast data into float type\n",
    "df['availability_30']= df['availability_30'].apply(lambda x: float(x))\n",
    "df['availability_60']= df['availability_60'].apply(lambda x: float(x))\n",
    "df['availability_90']= df['availability_90'].apply(lambda x: float(x))\n",
    "df['availability_365']= df['availability_365'].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate average number for null data\n",
    "def to_avg(c):\n",
    "    a= np.average(df[df[c]!=''][c].astype(float))\n",
    "    df[c]= df[c].replace('', a).astype(float)\n",
    "to_avg('bathrooms')\n",
    "to_avg('bedrooms')\n",
    "to_avg('beds')\n",
    "to_avg('host_listings_count')\n",
    "to_avg('host_total_listings_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set null data to 0\n",
    "df['cleaning_fee']= df['cleaning_fee'].replace('', 0)\n",
    "df['cleaning_fee']= df['cleaning_fee'].replace('[\\$,]', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill null data with 0 and set non-null data to 1\n",
    "def nll(string):\n",
    "    df[string]= df[string].notnull().astype('int')\n",
    "nll('access')\n",
    "nll('summary')\n",
    "nll('space')\n",
    "nll('notes')\n",
    "nll('transit')\n",
    "nll('host_name')\n",
    "nll('house_rules')\n",
    "nll('license')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deal with geo data: get city and state from longitude and latitude, and clean zipcode, host_location, and neighborhood_overview\n",
    "df.drop(['city','city_name','jurisdiction_names','neighbourhood','host_neighbourhood','street','state','country_code','country'], axis = 1, inplace = True)\n",
    "\n",
    "# longitude, latitude\n",
    "df['longitude']= df['longitude'].astype(float)\n",
    "df['latitude']=df['latitude'].astype(float)\n",
    "\n",
    "import reverse_geocoder as rg\n",
    "ww=tuple(zip(df['latitude'],df['longitude']))\n",
    "df['state']= np.array([i.get('admin1') for i in rg.search(ww)])\n",
    "df['city']= np.array([i.get('name') for i in rg.search(ww)])\n",
    "\n",
    "# zipcode\n",
    "df['zipcode']= df['zipcode'].apply(lambda x: x.replace('.0','')).replace('\\D', '', regex=True).apply(lambda x: x[:5])\n",
    "df.loc[df['zipcode'].apply(lambda x: len(x))!=5, 'zipcode'] = '00000'\n",
    "\n",
    "# host_location\n",
    "df['host_location']=df['host_location'].notnull().astype('int')\n",
    "\n",
    "#neighborhood_overview\n",
    "df['neighborhood_overview']=df['neighborhood_overview'].notnull().astype('int')\n",
    "df.drop(['smart_location'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For cateforical data, set null as 'no_data'.\n",
    "def to_no_data(c):\n",
    "    df[c]= df[c].replace('', 'no_data')\n",
    "to_no_data('host_response_time')\n",
    "to_no_data('market')\n",
    "to_no_data('property_type')\n",
    "to_no_data('room_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deal with date: convert date into days from now\n",
    "# first_review\n",
    "df['first_review']=df['first_review'].apply(lambda x: (dt.datetime.now() - datetime.strptime(x,'%Y-%m-%d')).days)\n",
    "# host_since\n",
    "df['host_since']=df['host_since'].apply(lambda x: (dt.datetime.now() - datetime.strptime(x,'%Y-%m-%d')).days if x else '')\n",
    "to_avg('host_since')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Strip symbols\n",
    "# extra_people\n",
    "df['extra_people']= df['extra_people'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# host_acceptance_rate\n",
    "df['host_acceptance_rate']= df['host_acceptance_rate'].replace('[%]', '', regex=True)\n",
    "to_avg('host_acceptance_rate')\n",
    "\n",
    "# host_response_rate\n",
    "df['host_response_rate']= df['host_response_rate'].replace('[%]', '', regex=True)\n",
    "to_avg('host_response_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change t, f into 1 and 0\n",
    "def to_f(col):\n",
    "    df[col]= df[col].replace(['f',''],'0').replace('t','1').astype(int)\n",
    "to_f('require_guest_phone_verification')\n",
    "to_f('requires_license')\n",
    "to_f('instant_bookable')\n",
    "to_f('is_location_exact')\n",
    "to_f('is_business_travel_ready')\n",
    "to_f('host_has_profile_pic')\n",
    "to_f('host_is_superhost')\n",
    "to_f('host_identity_verified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Expend host_verifications into columns\n",
    "a= df['host_verifications'].apply(lambda x: str(x))\n",
    "a= a.apply(lambda x: x.replace('None','[]'))\n",
    "a= a.apply(lambda x: x.replace('nan','[]'))\n",
    "a= a.replace('','[]')\n",
    "a= a.apply(lambda x: eval(x))\n",
    "b = a.apply(frozenset).to_frame(name='genre')\n",
    "for genre in frozenset.union(*b.genre):\n",
    "    b[genre] = b.apply(lambda _: int(genre in _.genre), axis=1)\n",
    "b=b.iloc[:,1:]\n",
    "df= pd.concat([df, b], axis=1)\n",
    "df.drop(['host_verifications'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# interaction\n",
    "df['interaction']=df['interaction'].notnull().astype('int')\n",
    "\n",
    "# maximum_nights\n",
    "df['maximum_nights']=df['maximum_nights'].replace('NA','365', regex=True).astype(float)\n",
    "df.loc[df['maximum_nights'] > 364, 'maximum_nights'] = 365\n",
    "\n",
    "# minimum_nights\n",
    "df['minimum_nights']=df['minimum_nights'].replace('NA','1', regex=True).astype(float)\n",
    "df.loc[df['minimum_nights'] > 364, 'minimum_nights'] = 365\n",
    "\n",
    "# monthly_price\n",
    "df['monthly_price']= df['monthly_price'].replace('', '0')\n",
    "df['monthly_price']= df['monthly_price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# name\n",
    "df.drop(['name'], axis = 1, inplace = True)\n",
    "\n",
    "# price\n",
    "df['price']= df['price'].replace('', '0')\n",
    "df['price']= df['price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# security_deposit\n",
    "df['security_deposit']= df['security_deposit'].replace('', '0')\n",
    "df['security_deposit']= df['security_deposit'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# weekly_price\n",
    "df['weekly_price']= df['weekly_price'].replace('', '0')\n",
    "df['weekly_price']= df['weekly_price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "df['weekly_discount']= df['price']*7-df['weekly_price']\n",
    "df.drop(['weekly_price'], axis = 1, inplace = True)\n",
    "\n",
    "df['monthly_discount']= df['price']*30-df['monthly_price']\n",
    "df.drop(['monthly_price'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Amenities\n",
    "import re\n",
    "a= df['amenities'].apply(lambda x : re.sub(r\"[^,\\w]+\",'',x).lower())\n",
    "a= a.apply(lambda x : x.split(','))\n",
    "b= a.apply(frozenset).to_frame(name='genre')\n",
    "for genre in frozenset.union(*b.genre):\n",
    "    b[genre] = b.apply(lambda _: int(genre in _.genre), axis=1)\n",
    "\n",
    "b['pets']= b['dogs'] + b['petsallowed'] + b['cats'] + b['otherpets']\n",
    "b['pets']= b['pets'].replace([2,3,4],1)\n",
    "\n",
    "b['tv']= b['tv'] + b['cabletv'] + b['smarttv']\n",
    "b['tv']= b['tv'].replace([2,3],1)\n",
    "\n",
    "b['elevator']= b['elevator'] + b['elevatorinbuilding']\n",
    "b['elevator']= b['elevator'].replace(2,1)\n",
    "\n",
    "b['freeparkingonstreet']= b['freeparkingonstreet'] + b['freestreetparking']\n",
    "b['freestreetparking']= b['freeparkingonstreet'].replace(2,1)\n",
    "\n",
    "b['frontdesk/doorperson']= b['frontdeskdoorperson'] + b['doorman']\n",
    "b['frontdesk/doorperson']= b['frontdesk/doorperson'].replace(2,1)\n",
    "\n",
    "b['wifi']= b['wifi'] + b['wirelessinternet']\n",
    "b['wifi']= b['wifi'].replace(2,1)\n",
    "\n",
    "b['oven']= b['oven'] + b['convectionoven']\n",
    "b['oven']= b['oven'].replace(2,1)\n",
    "\n",
    "b['widedoorway']= b['widedoorway'] + b['wideentryway']\n",
    "b['widedoorway']= b['widedoorway'].replace(2,1)\n",
    "\n",
    "b['wideclearancetoshowerandtoilet']= b['wideclearancetoshowerandtoilet'] + b['wideclearancetoshowertoilet']\n",
    "b['wideclearancetoshowerandtoilet']= b['wideclearancetoshowerandtoilet'].replace(2,1)\n",
    "\n",
    "b['welllitpathtoentrance']= b['welllitpathtoentrance'] + b['pathtoentrancelitatnight']\n",
    "b['lit_entrance']= b['welllitpathtoentrance'].replace(2,1)\n",
    "\n",
    "b['balcony']= b['balcony'] + b['patioorbalcony']\n",
    "b['balcony']= b['balcony'].replace(2,1)\n",
    "\n",
    "b['bathtub']= b['bathtub'] + b['soakingtub']\n",
    "b['bathtub']= b['bathtub'].replace(2,1)\n",
    "\n",
    "b['kitchen']= b['kitchen'] + b['kitchenette'] + b['fullkitchen']\n",
    "b['kitchen']= b['kitchen'].replace([2,3,4],1)\n",
    "\n",
    "b['flatpathtofrontdoor']= b['flatpathtofrontdoor'] + b['flatsmoothpathwaytofrontdoor'] + b['flatpathtofrontdoor'] + b['smoothpathwaytofrontdoor']\n",
    "b['flatpathtofrontdoor']= b['flatpathtofrontdoor'].replace([2,3,4],1)\n",
    "\n",
    "b['fixedgrabbarsforshower']= b['fixedgrabbarsforshower'] + b['fixedgrabbarsforshowertoilet']\n",
    "b['fixedgrabbarsforshower']= b['fixedgrabbarsforshower'].replace(2,1)\n",
    "\n",
    "b.drop(['genre', '', 'dogs', 'petsallowed', 'cats', 'otherpets','cabletv','smarttv','elevatorinbuilding', 'freeparkingonstreet','frontdeskdoorperson', 'doorman', 'wirelessinternet', 'convectionoven','fixedgrabbarsforshowertoilet', 'flatsmoothpathwaytofrontdoor', 'flatpathtofrontdoor', 'smoothpathwaytofrontdoor', 'kitchenette', 'fullkitchen', 'soakingtub', 'patioorbalcony', 'welllitpathtoentrance', 'pathtoentrancelitatnight', 'wideclearancetoshowertoilet', 'wideentryway'], axis = 1, inplace = True)\n",
    "df.drop(['amenities'], axis = 1, inplace = True)\n",
    "\n",
    "df = pd.concat([df,b], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Expand categories into columns\n",
    "def dum(col):\n",
    "    global df\n",
    "    a= pd.get_dummies(df[col].str.lower(),prefix=col)\n",
    "    df= pd.concat([df,a], axis = 1)\n",
    "    df= df.drop([col], axis = 1)\n",
    "dum('bed_type')\n",
    "dum('cancellation_policy')\n",
    "dum('host_response_time')\n",
    "dum('market')\n",
    "dum('property_type')\n",
    "dum('room_type')\n",
    "dum('city')\n",
    "dum('state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save to file\n",
    "df.to_csv('airbnb_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv('/Users/bonniechung/GoogleCloud/758T/project/raw_data/airbnb_test_x.csv', header = 0, index_col = 0, keep_default_na=False, dtype={\"zipcode\":str, 'maximum_nights':str, 'minimum_nights':str, 'availability_30':str, 'availability_60':str, 'availability_90':str, 'availability_365':str })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop missing or invalid records\n",
    "df.drop([775,10274], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "df.drop(['require_guest_profile_picture'], axis = 1, inplace = True) # All of the values are false\n",
    "df.drop(['square_feet'], axis = 1, inplace = True) # Having too less records\n",
    "df.drop(['experiences_offered'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the length of text data\n",
    "df['len_access']= df['access'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_description']= df['description'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_host_about']= df['host_about'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_house_rules']= df['house_rules'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_interaction']= df['interaction'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_name']= df['name'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_neighborhood_overview']= df['neighborhood_overview'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_notes']= df['notes'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_space']= df['space'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_summary']= df['summary'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))\n",
    "df['len_transit']= df['transit'].replace(\"[^a-zA-Z0-9' ]\", '',regex=True).apply(lambda x:len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['description','host_about'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cast data into float type\n",
    "df['availability_30']= df['availability_30'].apply(lambda x: float(x))\n",
    "df['availability_60']= df['availability_60'].apply(lambda x: float(x))\n",
    "df['availability_90']= df['availability_90'].apply(lambda x: float(x))\n",
    "df['availability_365']= df['availability_365'].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate average number for null data\n",
    "def to_avg(c):\n",
    "    a= np.average(df[df[c]!=''][c].astype(float))\n",
    "    df[c]= df[c].replace('', a).astype(float)\n",
    "to_avg('bathrooms')\n",
    "to_avg('bedrooms')\n",
    "to_avg('beds')\n",
    "to_avg('host_listings_count')\n",
    "to_avg('host_total_listings_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set null data to 0\n",
    "df['cleaning_fee']= df['cleaning_fee'].replace('', 0)\n",
    "df['cleaning_fee']= df['cleaning_fee'].replace('[\\$,]', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill null data with 0 and set non-null data to 1\n",
    "def nll(string):\n",
    "    df[string]= df[string].notnull().astype('int')\n",
    "nll('access')\n",
    "nll('summary')\n",
    "nll('space')\n",
    "nll('notes')\n",
    "nll('transit')\n",
    "nll('host_name')\n",
    "nll('house_rules')\n",
    "nll('license')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deal with geo data: get city and state from longitude and latitude, and clean zipcode, host_location, and neighborhood_overview\n",
    "df.drop(['city','city_name','jurisdiction_names','neighbourhood','host_neighbourhood','street','state','country_code','country'], axis = 1, inplace = True)\n",
    "\n",
    "# longitude, latitude\n",
    "df['longitude']= df['longitude'].replace('',0, regex=True).astype(float)\n",
    "df['latitude']=df['latitude'].replace('',0, regex=True).astype(float)\n",
    "\n",
    "import reverse_geocoder as rg\n",
    "ww=tuple(zip(df['latitude'],df['longitude']))\n",
    "df['state']= np.array([i.get('admin1') for i in rg.search(ww)])\n",
    "df['city']= np.array([i.get('name') for i in rg.search(ww)])\n",
    "\n",
    "# zipcode\n",
    "df['zipcode']= df['zipcode'].apply(lambda x: x.replace('.0','')).replace('\\D', '', regex=True).apply(lambda x: x[:5])\n",
    "df.loc[df['zipcode'].apply(lambda x: len(x))!=5, 'zipcode'] = '00000'\n",
    "\n",
    "# host_location\n",
    "df['host_location']=df['host_location'].notnull().astype('int')\n",
    "\n",
    "#neighborhood_overview\n",
    "df['neighborhood_overview']=df['neighborhood_overview'].notnull().astype('int')\n",
    "df.drop(['smart_location'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For cateforical data, set null as 'no_data'.\n",
    "def to_no_data(c):\n",
    "    df[c]= df[c].replace('', 'no_data')\n",
    "to_no_data('host_response_time')\n",
    "to_no_data('market')\n",
    "to_no_data('property_type')\n",
    "to_no_data('room_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deal with date: convert date into days from now\n",
    "# first_review\n",
    "df['first_review']=df['first_review'].apply(lambda x: (dt.datetime.now() - datetime.strptime(x,'%Y-%m-%d')).days)\n",
    "# host_since\n",
    "df['host_since']=df['host_since'].apply(lambda x: (dt.datetime.now() - datetime.strptime(x,'%Y-%m-%d')).days if x else '')\n",
    "to_avg('host_since')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Strip symbols\n",
    "# extra_people\n",
    "df['extra_people']= df['extra_people'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# host_acceptance_rate\n",
    "df['host_acceptance_rate']= df['host_acceptance_rate'].replace('[%]', '', regex=True)\n",
    "to_avg('host_acceptance_rate')\n",
    "\n",
    "# host_response_rate\n",
    "df['host_response_rate']= df['host_response_rate'].replace('[%]', '', regex=True)\n",
    "to_avg('host_response_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change t, f into 1 and 0\n",
    "def to_f(col):\n",
    "    df[col]= df[col].replace(['f',''],'0').replace('t','1').astype(int)\n",
    "to_f('require_guest_phone_verification')\n",
    "to_f('requires_license')\n",
    "to_f('instant_bookable')\n",
    "to_f('is_location_exact')\n",
    "to_f('is_business_travel_ready')\n",
    "to_f('host_has_profile_pic')\n",
    "to_f('host_is_superhost')\n",
    "to_f('host_identity_verified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Expend host_verifications into columns\n",
    "a= df['host_verifications'].apply(lambda x: str(x))\n",
    "a= a.apply(lambda x: x.replace('None','[]'))\n",
    "a= a.apply(lambda x: x.replace('nan','[]'))\n",
    "a= a.replace('','[]')\n",
    "a= a.apply(lambda x: eval(x))\n",
    "b = a.apply(frozenset).to_frame(name='genre')\n",
    "for genre in frozenset.union(*b.genre):\n",
    "    b[genre] = b.apply(lambda _: int(genre in _.genre), axis=1)\n",
    "b=b.iloc[:,1:]\n",
    "df= pd.concat([df, b], axis=1)\n",
    "df.drop(['host_verifications'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# interaction\n",
    "df['interaction']=df['interaction'].notnull().astype('int')\n",
    "\n",
    "# maximum_nights\n",
    "df['maximum_nights']=df['maximum_nights'].replace('NA','365', regex=True).astype(float)\n",
    "df.loc[df['maximum_nights'] > 364, 'maximum_nights'] = 365\n",
    "\n",
    "# minimum_nights\n",
    "df['minimum_nights']=df['minimum_nights'].replace('NA','1', regex=True).astype(float)\n",
    "df.loc[df['minimum_nights'] > 364, 'minimum_nights'] = 365\n",
    "\n",
    "# monthly_price\n",
    "df['monthly_price']= df['monthly_price'].replace('', '0')\n",
    "df['monthly_price']= df['monthly_price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# name\n",
    "df.drop(['name'], axis = 1, inplace = True)\n",
    "\n",
    "# price\n",
    "df['price']= df['price'].replace('', '0')\n",
    "df['price']= df['price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# security_deposit\n",
    "df['security_deposit']= df['security_deposit'].replace('', '0')\n",
    "df['security_deposit']= df['security_deposit'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# weekly_price\n",
    "df['weekly_price']= df['weekly_price'].replace('', '0')\n",
    "df['weekly_price']= df['weekly_price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "df['weekly_discount']= df['price']*7-df['weekly_price']\n",
    "df.drop(['weekly_price'], axis = 1, inplace = True)\n",
    "\n",
    "df['monthly_discount']= df['price']*30-df['monthly_price']\n",
    "df.drop(['monthly_price'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Amenities\n",
    "import re\n",
    "a= df['amenities'].apply(lambda x : re.sub(r\"[^,\\w]+\",'',x).lower())\n",
    "a= a.apply(lambda x : x.split(','))\n",
    "b= a.apply(frozenset).to_frame(name='genre')\n",
    "for genre in frozenset.union(*b.genre):\n",
    "    b[genre] = b.apply(lambda _: int(genre in _.genre), axis=1)\n",
    "\n",
    "b['pets']= b['dogs'] + b['petsallowed'] + b['cats'] + b['otherpets']\n",
    "b['pets']= b['pets'].replace([2,3,4],1)\n",
    "\n",
    "b['tv']= b['tv'] + b['cabletv'] + b['smarttv']\n",
    "b['tv']= b['tv'].replace([2,3],1)\n",
    "\n",
    "b['elevator']= b['elevator'] + b['elevatorinbuilding']\n",
    "b['elevator']= b['elevator'].replace(2,1)\n",
    "\n",
    "b['freeparkingonstreet']= b['freeparkingonstreet'] + b['freestreetparking']\n",
    "b['freestreetparking']= b['freeparkingonstreet'].replace(2,1)\n",
    "\n",
    "b['frontdesk/doorperson']= b['frontdeskdoorperson'] + b['doorman']\n",
    "b['frontdesk/doorperson']= b['frontdesk/doorperson'].replace(2,1)\n",
    "\n",
    "b['wifi']= b['wifi'] + b['wirelessinternet']\n",
    "b['wifi']= b['wifi'].replace(2,1)\n",
    "\n",
    "b['oven']= b['oven'] + b['convectionoven']\n",
    "b['oven']= b['oven'].replace(2,1)\n",
    "\n",
    "b['widedoorway']= b['widedoorway'] + b['wideentryway']\n",
    "b['widedoorway']= b['widedoorway'].replace(2,1)\n",
    "\n",
    "b['welllitpathtoentrance']= b['welllitpathtoentrance'] + b['pathtoentrancelitatnight']\n",
    "b['lit_entrance']= b['welllitpathtoentrance'].replace(2,1)\n",
    "\n",
    "b['balcony']= b['balcony'] + b['patioorbalcony']\n",
    "b['balcony']= b['balcony'].replace(2,1)\n",
    "\n",
    "b['bathtub']= b['bathtub'] + b['soakingtub']\n",
    "b['bathtub']= b['bathtub'].replace(2,1)\n",
    "\n",
    "b['kitchen']= b['kitchen'] + b['fullkitchen']\n",
    "b['kitchen']= b['kitchen'].replace([2,3,4],1)\n",
    "\n",
    "b['flatpathtofrontdoor']= b['flatpathtofrontdoor'] + b['flatpathtofrontdoor'] + b['smoothpathwaytofrontdoor']\n",
    "b['flatpathtofrontdoor']= b['flatpathtofrontdoor'].replace([2,3,4],1)\n",
    "\n",
    "b['fixedgrabbarsforshower']= b['fixedgrabbarsforshower'] + b['fixedgrabbarsforshowertoilet']\n",
    "b['fixedgrabbarsforshower']= b['fixedgrabbarsforshower'].replace(2,1)\n",
    "\n",
    "b.drop(['genre', '', 'dogs', 'petsallowed', 'cats', 'otherpets','cabletv','smarttv','elevatorinbuilding', 'freeparkingonstreet','frontdeskdoorperson', 'doorman', 'wirelessinternet', 'convectionoven','fixedgrabbarsforshowertoilet', 'flatpathtofrontdoor', 'smoothpathwaytofrontdoor', 'fullkitchen', 'soakingtub', 'patioorbalcony', 'welllitpathtoentrance', 'pathtoentrancelitatnight', 'wideclearancetoshowertoilet', 'wideentryway'], axis = 1, inplace = True)\n",
    "df.drop(['amenities'], axis = 1, inplace = True)\n",
    "\n",
    "df = pd.concat([df,b], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Expand categories into columns\n",
    "def dum(col):\n",
    "    global df\n",
    "    a= pd.get_dummies(df[col].str.lower(),prefix=col)\n",
    "    df= pd.concat([df,a], axis = 1)\n",
    "    df= df.drop([col], axis = 1)\n",
    "dum('bed_type')\n",
    "dum('cancellation_policy')\n",
    "dum('host_response_time')\n",
    "dum('market')\n",
    "dum('property_type')\n",
    "dum('room_type')\n",
    "dum('city')\n",
    "dum('state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t= pd.read_csv('airbnb_train.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in t.keys():\n",
    "    if i not in df.keys():\n",
    "        df[str(i)]=np.zeros(len(df), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df= df[list(t.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save to file\n",
    "df.to_csv('airbnb_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1 Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('airbnb_train.csv', header = 0, index_col = 0)\n",
    "df_t= pd.read_csv('airbnb_test.csv', header = 0, index_col = 0)\n",
    "df_g = pd.read_csv('/Users/bonniechung/GoogleCloud/758T/project/raw_raw/airbnb_geo.csv',encoding='utf-8',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= (df[['longitude','latitude']].round(6)*1000000).astype(int)\n",
    "a= a.reset_index()\n",
    "b= df_g[df_g['longitude'].notnull()][['longitude','latitude','review_scores_accuracy','reviews_per_month','review_scores_communication',\n",
    "                                      'review_scores_cleanliness','review_scores_location','review_scores_rating'\n",
    "                                      ,'review_scores_value','number_of_reviews']]\n",
    "b.columns=['longitude','latitude','review_scores_accuracy','reviews_per_month','review_scores_communication',\n",
    "                                      'review_scores_cleanliness','review_scores_location','review_scores_rating2'\n",
    "                                      ,'review_scores_value','number_of_reviews']\n",
    "b[['longitude','latitude']]=(b[['longitude','latitude']].round(6)*1000000).astype(int)\n",
    "a[a[['longitude','latitude']].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[b[['longitude','latitude']].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c= pd.merge(a,b, how='left',on=['longitude','latitude'])\n",
    "c= c.set_index('index')\n",
    "del c.index.name\n",
    "c.drop(['longitude','latitude'], axis = 1, inplace = True)\n",
    "df= pd.concat([df,c],axis=1)\n",
    "df[['review_scores_accuracy','reviews_per_month','review_scores_communication', 'review_scores_cleanliness',\n",
    "    'review_scores_location','review_scores_rating2','review_scores_value',\n",
    "    'number_of_reviews']]= df[['review_scores_accuracy','reviews_per_month',\n",
    "                               'review_scores_communication','review_scores_cleanliness','review_scores_location',\n",
    "                               'review_scores_rating2','review_scores_value','number_of_reviews']].fillna(0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= (df_t[['longitude','latitude']].round(6)*1000000).astype(int)\n",
    "a= a.reset_index()\n",
    "a[a[['longitude','latitude']].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c= pd.merge(a,b, how='left',on=['longitude','latitude'])\n",
    "c= c.set_index('index')\n",
    "del c.index.name\n",
    "c.drop(['longitude','latitude'], axis = 1, inplace = True)\n",
    "df_t= pd.concat([df_t,c],axis=1)\n",
    "df_t[['review_scores_accuracy','reviews_per_month','review_scores_communication', 'review_scores_cleanliness',\n",
    "    'review_scores_location','review_scores_rating2','review_scores_value',\n",
    "    'number_of_reviews']]= df_t[['review_scores_accuracy','reviews_per_month',\n",
    "                               'review_scores_communication','review_scores_cleanliness','review_scores_location',\n",
    "                               'review_scores_rating2','review_scores_value','number_of_reviews']].fillna(0).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1-1 Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training data\n",
    "a = StandardScaler().fit_transform(df.iloc[:,2:].values)\n",
    "b = pd.DataFrame(a, index=df.iloc[:,2:].index, columns=df.iloc[:,2:].columns)\n",
    "df = pd.concat([df.iloc[:,:2],b],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing data\n",
    "a = StandardScaler().fit_transform(df_t.values)\n",
    "df_t = pd.DataFrame(a, index=df_t.index, columns=df_t.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2 Split data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(df.iloc[:,2:], df.iloc[:,1], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3 XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, train_x=train_x ,train_y=train_y, test_x=test_x, test_y=test_y, \n",
    "             useTrainCV=True, cv_folds=5, early_stopping_rounds=100):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(train_x.values, label=train_y.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds,verbose_eval=True)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "        \n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(train_x, train_y,eval_metric='auc')\n",
    "    print(alg)\n",
    "        \n",
    "    #Predict training set:\n",
    "    train_predictions = alg.predict(train_x)\n",
    "    train_predprob = alg.predict_proba(train_x)[:,1]\n",
    "\n",
    "    #Predict testing set:\n",
    "    test_predictions = alg.predict(test_x)\n",
    "    test_predprob = alg.predict_proba(test_x)[:,1]\n",
    "    \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy (Train): %.4g\" % metrics.accuracy_score(train_y.values, train_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(train_y, train_predprob))\n",
    "    print(\"Accuracy (Test): %.4g\" % metrics.accuracy_score(test_y.values, test_predictions))\n",
    "    print(\"AUC Score (Test): %f\" % metrics.roc_auc_score(test_y, test_predprob))\n",
    "\n",
    "    feat_imp = pd.Series(alg.get_booster().get_fscore()).sort_values(ascending=False).head(30)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get best n_estimator with cross-validation\n",
    "xgb1 = XGBClassifier(n_estimators=10000,n_jobs=3,seed=2 )\n",
    "modelfit(xgb1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3-1 Tune Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':list(range(3,6,2)),\n",
    " 'min_child_weight':list(range(1,6,2))\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, n_estimators=2362, max_depth=5,min_child_weight=1, \n",
    "                                    gamma=0, subsample=0.8, colsample_bytree=0.8,objective= 'binary:logistic', \n",
    "                                    n_jobs=3, scale_pos_weight=1, seed=2), \n",
    "                        param_grid = param_test1, scoring='roc_auc',n_jobs=2,iid=False, cv=5)\n",
    "gsearch1.fit(train_x,train_y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[2,3,4],\n",
    " 'min_child_weight':[4,5,6]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, n_estimators=2362, max_depth=3,\n",
    "                                    min_child_weight=5, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                    objective= 'binary:logistic', n_jobs=3, scale_pos_weight=1,seed=2), \n",
    "                         param_grid = param_test2, scoring='roc_auc',n_jobs=2,iid=False, cv=5)\n",
    "gsearch2.fit(train_x,train_y)\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test2b = {\n",
    " 'min_child_weight':[6,8,10,12]\n",
    "}\n",
    "gsearch2b = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, n_estimators=2362, max_depth=4,\n",
    "                                     min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                     objective= 'binary:logistic', n_jobs=3, scale_pos_weight=1,seed=2), \n",
    "                         param_grid = param_test2b, scoring='roc_auc',n_jobs=2,iid=False, cv=5)\n",
    "gsearch2b.fit(train_x,train_y)\n",
    "gsearch2b.grid_scores_, gsearch2b.best_params_, gsearch2b.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=3000, max_depth=4,\n",
    "                                    min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                    objective= 'binary:logistic', n_jobs=3, scale_pos_weight=1,seed=2), \n",
    "                        param_grid = param_test3, scoring='roc_auc',n_jobs=2,iid=False, cv=5)\n",
    "gsearch3.fit(train_x,train_y)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, n_estimators=2362, max_depth=4,\n",
    "                                    min_child_weight=6, gamma=0.3, subsample=0.8, colsample_bytree=0.8,\n",
    "                                    objective= 'binary:logistic', n_jobs=3, scale_pos_weight=1,seed=2), \n",
    "                        param_grid = param_test4, scoring='roc_auc',n_jobs=2,iid=False, cv=5)\n",
    "gsearch4.fit(train_x,train_y)\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test5 = {\n",
    " 'subsample':[i/100.0 for i in range(75,90,5)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(75,90,5)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, n_estimators=2362, max_depth=4,\n",
    "                                    min_child_weight=6, gamma=0.3, subsample=0.8, colsample_bytree=0.8,\n",
    "                                    objective= 'binary:logistic', n_jobs=3, scale_pos_weight=1,seed=2), \n",
    "                        param_grid = param_test5, scoring='roc_auc',n_jobs=2,iid=False, cv=5)\n",
    "gsearch5.fit(train_x,train_y)\n",
    "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[1e-6, 1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, n_estimators=2362, max_depth=4,\n",
    "                                    min_child_weight=6, gamma=0.3, subsample=0.85, colsample_bytree=0.85,\n",
    "                                    objective= 'binary:logistic', n_jobs=3, scale_pos_weight=1,seed=2), \n",
    "                        param_grid = param_test6, scoring='roc_auc',n_jobs=2,iid=False, cv=5)\n",
    "gsearch6.fit(train_x,train_y)\n",
    "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test7 = {\n",
    " 'reg_alpha':list(np.arange(1e-06,1e-04,0.00002))\n",
    "}\n",
    "gsearch7 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, n_estimators=2362, max_depth=4,\n",
    "                                    min_child_weight=6, gamma=0.3, subsample=0.85, colsample_bytree=0.85,\n",
    "                                    objective= 'binary:logistic', n_jobs=3, scale_pos_weight=1,seed=2), \n",
    "                        param_grid = param_test7, scoring='roc_auc',n_jobs=2,iid=False, cv=5)\n",
    "gsearch7.fit(train_x,train_y)\n",
    "gsearch7.grid_scores_, gsearch7.best_params_, gsearch7.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_tune = XGBClassifier(learning_rate =0.1, n_estimators=2362, max_depth=4,min_child_weight=6, gamma=0.3, \n",
    "                     subsample=0.85, colsample_bytree=0.85,objective= 'binary:logistic', n_jobs=3, \n",
    "                     scale_pos_weight=1,seed=2)\n",
    "modelfit(xgb_tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4 Use all training data to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = df.iloc[:,2:]\n",
    "train_y = df.iloc[:,1]\n",
    "test_x  = df_t.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb2 = XGBClassifier(n_estimators=4000,n_jobs=3,seed=2)\n",
    "xgb_param = xgb2.get_xgb_params()\n",
    "xgtrain = xgb.DMatrix(train_x.values, label=train_y.values)\n",
    "cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=xgb2.get_params()['n_estimators'], \n",
    "                  nfold=5,metrics='auc', early_stopping_rounds=150)\n",
    "xgb2.set_params(n_estimators=cvresult.shape[0])\n",
    "xgb2.fit(train_x, train_y,eval_metric='auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-5 Fit testing data into the model and output the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = xgb2.predict(test_x)\n",
    "predictions= list(predictions)\n",
    "predictions.insert(774,0)\n",
    "predictions.insert(10273,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(predictions, columns=['high_booking_rate'],index=np.arange(1,12209)).to_csv('raw_0427.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
